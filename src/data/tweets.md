# Tweet

Ever wondered how to reproduce GPT-2 (124M) efficiently?
@karpathy with llm.c has the answer!

- 90 mins, $20 on 8X A100 80GB SXM
- FineWeb dataset: 10B tokens
- MFU: 49-60%, 178K tokens/sec

https://github.com/karpathy/llm.c/discussions/481